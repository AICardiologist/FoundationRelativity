\documentclass[11pt]{article}

% -------------------------------------------------
% Preamble
% -------------------------------------------------
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\IfFileExists{lmodern.sty}{\usepackage{lmodern}}{}
\usepackage{geometry}
\geometry{margin=1in}

\usepackage{amsmath,amssymb}
\usepackage{amsthm}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue}
\usepackage{xcolor}
\usepackage{booktabs}

% mdframed with fallback
\IfFileExists{mdframed.sty}{
  \usepackage{mdframed}
  \mdfdefinestyle{status}{backgroundcolor=gray!10,linecolor=gray!60!black,linewidth=0.8pt,
    innerleftmargin=6pt,innerrightmargin=6pt,innertopmargin=4pt,innerbottommargin=4pt}
}{
  \newenvironment{mdframed}[1][]{\begin{quote}\itshape}{\end{quote}}
}

% Code formatting - using fancyvrb for Unicode support
\usepackage{fancyvrb}
\DefineVerbatimEnvironment{leancode}{Verbatim}{fontsize=\small,commandchars=\\\{\}}

% -------------------------------------------------
% Theorem styles
% -------------------------------------------------
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% -------------------------------------------------
% Macros
% -------------------------------------------------
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\AxCal}{\textsc{AxCal}}
\newcommand{\Christoffel}[3]{\Gamma^{#1}_{#2#3}}
\newcommand{\Riemann}[4]{R^{#1}_{#2#3#4}}
\newcommand{\Ricci}[2]{R_{#1#2}}

% -------------------------------------------------
% Title
% -------------------------------------------------
\title{Formalizing Schwarzschild Curvature in Lean 4:\\
A Machine-Checked Coordinate Pipeline\\
and a Methodology for Tracking Axiomatic Dependencies}

\author{Paul Chun--Kit Lee\\
\texttt{dr.paul.c.lee@gmail.com}\\
New York University, NY}

\date{February 2026}

\begin{document}
\maketitle

\begin{abstract}
We present a fully machine-checked verification of the standard textbook \emph{coordinate} curvature pipeline for Schwarzschild spacetime in Lean~4, comprising roughly 16{,}000 lines of code. The formalization verifies the pipeline
\[
g_{\mu\nu}\ \to\ \Gamma^{\rho}{}_{\mu\nu}\ \to\ R^{\rho}{}_{\sigma\mu\nu}\ \to\ R_{\mu\nu}\ \to\ K
\]
in the exterior region ($r>2M$) away from the coordinate axis ($0<\theta<\pi$), culminating in the vacuum condition $R_{\mu\nu}=0$ and the Kretschmann invariant $K=48M^2/r^6$.

The underlying mathematics is classical and well known; the novelty is methodological. The development exposes a large ``implicit-to-explicit'' gap between informal tensor calculus and machine-checked proofs, and it provides a concrete, reproducible benchmark for coordinate-based General Relativity in a modern proof assistant. Related mechanizations of relativity often focus on axiomatic or first-order treatments (typically of special relativity) rather than end-to-end coordinate curvature computation; we briefly situate our scope in Section~\ref{sec:related}.

We also introduce \emph{Axiom Calibration} (\AxCal{}), an organizational methodology for tracking which foundational ``portals'' (choice, compactness, classical logic) are invoked by different proof routes in physics. For the Schwarzschild vacuum verification (G1), the mathematics is finite symbolic computation; nevertheless, the formal development depends on classical infrastructure from \texttt{mathlib}. We therefore emphasize \emph{structural certification} (absence of high-level portals in the proof route) and outline how one could strengthen this into a mechanical axiom audit inside Lean (Section~\ref{sec:axcal}).

\medskip
\noindent\textbf{Artifact status (as of this draft):} no \texttt{sorry} placeholders in the GR development; GR target build is $\sim$4.2s (incremental warm cache, Feb~4~2026) and $\sim$2m10s for the first warm build after a full dependency build; clean full-repo build is $\sim$1h12m on the author machine (details in Section~\ref{sec:artifact}).
\end{abstract}

\begin{mdframed}[backgroundcolor=gray!10, linewidth=0pt]
\textbf{Scope and Honest Claims}

This paper reports on \emph{engineering} and \emph{methodology}, not new mathematics or physics. The Schwarzschild calculations we verify are standard textbook material \cite{Wald1984,MTW1973,Carroll2004}. The verification that these calculations are ``Height 0'' (constructive at the proof-route level) is unsurprising---they are finite symbolic computations.

The value lies in:
\begin{itemize}
\item Demonstrating that formal GR is feasible in Lean 4
\item Documenting the obstacles that made it difficult
\item Providing infrastructure for future, more ambitious formalizations
\item Introducing \AxCal{} as organizational methodology (not foundational breakthrough)
\end{itemize}

The more interesting GR results (G2--G5) are analyzed at the paper level but \emph{not formalized}. Their axiomatic profiles are asserted based on standard proof analysis, not machine-verified.
\end{mdframed}

\tableofcontents
\newpage

% ===================================================================
% PART 1: INTRODUCTION AND MOTIVATION
% ===================================================================

\section{Introduction}
\label{sec:intro}

\subsection{What This Paper Is (And Is Not)}

This paper reports a fully machine-checked verification of Schwarzschild spacetime curvature calculations in Lean~4, following the standard coordinate pipeline. We verify the standard textbook pipeline:
\begin{center}
Schwarzschild metric $\to$ Christoffel symbols $\to$ Riemann tensor $\to$ Ricci tensor $\to$ Kretschmann scalar
\end{center}
in Lean 4, with approximately 16,000 lines of code that builds without errors or \texttt{sorry} placeholders on the critical path.

\paragraph{What this paper is:}
\begin{itemize}
\item A \textbf{technique paper} demonstrating feasibility of formal GR verification
\item A \textbf{case study} in multi-AI agent collaboration for theorem proving
\item An \textbf{organizational framework} (\AxCal{}) for tracking axiomatic dependencies in physics
\item \textbf{Documentation} of why formalizing ``trivial'' mathematics is hard
\end{itemize}

\paragraph{What this paper is not:}
\begin{itemize}
\item New mathematics (the Schwarzschild calculations are 100+ years old)
\item New physics (we verify known results, not discover new ones)
\item A foundational breakthrough (the \AxCal{} framework applies known meta-mathematics)
\item Complete GR formalization (we handle only one solution in one coordinate patch)
\end{itemize}

\subsection{Related Work and Scope}
\label{sec:related}

There is an existing literature on mechanizing relativity in proof assistants, but much of it targets \emph{axiomatic} or \emph{first-order} formulations (often of special relativity) rather than explicit coordinate curvature computation. For example, Schutz-style axioms for Minkowski spacetime have been mechanized in Isabelle/HOL,\footnote{\url{https://arxiv.org/abs/2108.10868}} and first-order relativity theories have been verified in Isabelle/HOL.\footnote{\url{https://doi.org/10.1007/s10817-013-9292-7}} These efforts illuminate the logical structure of relativity and make axioms explicit, but they are intentionally far from the ``compute $\Gamma$, then $R$, then contract'' workflow familiar from GR textbooks.

The scope of this paper is complementary: we focus on the \emph{textbook coordinate pipeline} for a single classical solution, in a single chart, with all side conditions made explicit. Our claim is not that we are the first to formalize ``relativity,'' but that end-to-end, machine-checked coordinate curvature computations remain rare, and that they expose a distinct set of engineering bottlenecks (index expansion, side-condition threading, and controlled simplification) that are largely orthogonal to the axiomatic-first-order line of work.

\paragraph{Author context.}
The author is a practicing physician (interventional cardiology) with interests in formal methods and mathematical physics, but no professional training in either field. This project was undertaken as an exercise in learning Lean 4 and exploring the feasibility of formal verification in physics. Readers should evaluate the artifact on its technical merits; domain experts may find opportunities for improvement that a non-specialist would miss.

\subsection{Motivation: Searching for Hidden Axioms}

The original motivation for this project was foundational: \emph{What axioms does General Relativity actually require?}

Standard GR textbooks use the Axiom of Choice (via Zorn's lemma), compactness arguments (Ascoli-Arzel\`a), and proof by contradiction without flagging these as philosophically significant. For a constructive mathematician or a reverse mathematician, these hidden dependencies matter.

We sought to make them explicit by:
\begin{enumerate}
\item Formalizing GR results in a proof assistant
\item Tracking which axiom ``portals'' each proof crosses
\item Assigning ``height'' profiles measuring axiomatic strength
\end{enumerate}

\paragraph{The irony.} We formalized the \emph{easiest} case first: the Schwarzschild vacuum check (G1). This calculation has \textbf{no hidden axioms}---it is finite symbolic computation, obviously constructive. The ``discovery'' that G1 is Height 0 is tautological.

The interesting cases---where hidden axioms actually appear---are:
\begin{itemize}
\item \textbf{G2 (Cauchy problem/MGHD):} Zorn's lemma for maximality
\item \textbf{G3 (Singularity theorems):} Compactness + proof by contradiction
\item \textbf{G4 (Maximal extensions):} Zorn's lemma
\item \textbf{G5 (Computable evolution):} Pour-El--Richards \cite{PourElRichards1989} shows this \emph{fails}
\end{itemize}

These are analyzed at the paper level but \textbf{not formalized}. Formalizing them would be dramatically harder and remains future work.

\subsection{Why Bother Formalizing the Easy Case?}

If G1 has no hidden axioms, why spend six months formalizing it?

\begin{enumerate}
\item \textbf{Proof of concept:} Before attempting G2--G5, we needed to know that formal GR is feasible at all. Schwarzschild establishes the infrastructure.

\item \textbf{The gap is informative:} The difficulty of formalizing G1 reveals how much implicit reasoning standard mathematics employs. This gap is itself a finding.

\item \textbf{Infrastructure for future work:} The tensor calculus machinery (index types, summation helpers, differentiability lemmas) built for G1 transfers to other spacetimes.

\item \textbf{Benchmark artifact:} We are not aware of a prior end-to-end, machine-checked \emph{coordinate} curvature calculation for Schwarzschild (metric $\to$ Christoffel $\to$ Riemann $\to$ Ricci $\to$ Kretschmann) in an interactive theorem prover; if such an artifact exists, we would be happy to cite it. Either way, the present development serves as a concrete benchmark for ``proof-producing'' coordinate GR.
\end{enumerate}

\subsection{Paper Contributions}

\begin{enumerate}
\item \textbf{Artifact:} Lean~4 formalization of Schwarzschild curvature (Christoffel $\to$ Riemann $\to$ Ricci $\to$ Kretschmann). Zero errors, zero sorries in the GR folder. ~16,000 lines.

\item \textbf{Difficulty Analysis:} Documentation of why ``trivial'' GR calculations require 16,000 lines and 6 months. The gap between informal and formal mathematics is larger than expected.

\item \textbf{\AxCal{} Methodology:} An organizational framework for tracking axiom usage in physics proofs, with four ``portals'' (Zorn, limit-curve, serial-chain, reductio) and three-axis height profiles.

\item \textbf{Multi-AI Workflow:} Case study of Claude Code (Opus 4.5) + GPT-5.2 + Gemini 2.5 Pro Deep Think + GPT-5.2 Codex collaboration, documenting how different AI strengths complement each other.

\item \textbf{Roadmap:} Analysis of G2--G5 at the paper level, providing targets for future formalization.
\end{enumerate}

% ===================================================================
% PART 2: WHY FORMALIZATION IS HARD
% ===================================================================

\section{Why ``Trivial'' Mathematics Is Hard to Formalize}
\label{sec:difficulty}

The Schwarzschild vacuum check is a textbook calculation that any GR graduate student can do by hand in an afternoon. Yet formalizing it required:
\begin{itemize}
\item 16,000 lines of Lean 4 code
\item roughly 6 months of development
\item 4 collaborating AI agents
\item Numerous false starts and refactorings
\end{itemize}

This section documents why.

\subsection{The Index Machinery Problem}

\paragraph{On paper:} Write $\Gamma^\alpha_{\mu\nu}$ and everyone understands.

\paragraph{In Lean:} We must define:
\begin{itemize}
\item An \texttt{Idx} inductive type with constructors \texttt{t}, \texttt{r}, \texttt{$\theta$}, \texttt{$\varphi$}
\item A \texttt{sumIdx} function implementing $\sum_{\mu}$ over this finite type
\item Expansion lemmas showing $\texttt{sumIdx}~f = f(t) + f(r) + f(\theta) + f(\varphi)$
\item Normalization lemmas for rearranging sums
\end{itemize}

The Kretschmann scalar involves $R_{abcd} R^{abcd}$---a sum over $4^4 = 256$ index combinations. Managing this requires:
\begin{itemize}
\item \texttt{sumIdx2\_expand} for double sums
\item \texttt{sixBlock} decomposition exploiting Riemann symmetries
\item Weight normalization lemmas (\texttt{weight\_xyxy}, \texttt{weight\_xyyx}, etc.)
\end{itemize}

None of this exists in \texttt{mathlib}. We built it from scratch.

\subsection{The Side Condition Problem}

\paragraph{On paper:} ``Clearly $r \neq 2M$ and $\sin\theta \neq 0$.''

\paragraph{In Lean:} Every division requires a proof. The expression $f(r)^{-1}$ where $f(r) = 1 - 2M/r$ demands:
\begin{leancode}
hf : f M r \\neq 0
\end{leancode}

In practice we package the exterior-domain constraints in a dedicated predicate so that common nonvanishing facts (e.g. $r\neq 0$ and $f(M,r)\neq 0$) can be recovered uniformly and reused by \texttt{field\_simp} and derivative lemmas:
\begin{leancode}
structure Exterior (M r \\theta : \\mathbb{R}) : Prop where
  hM : 0 < M
  hr_ex : 2 * M < r
\end{leancode}

The remaining coordinate restriction $0<\theta<\pi$ is tracked separately (it is needed only to deduce $\sin\theta\neq 0$ so that $g^{\varphi\varphi}$ is well-defined in this chart). Bundling and reusing these hypotheses is one of the main ``hidden costs'' of formalization: every division, derivative rule, and simplification step demands an explicit proof obligation that is usually implicit on paper.

\subsection{The Tactic Fragility Problem}

Early proof attempts used aggressive automation:
\begin{leancode}
simp [Riemann, Christoffel, g, gInv, f, ...]
\end{leancode}

This caused:
\begin{itemize}
\item \textbf{Timeouts:} Expanding all definitions creates expressions with thousands of terms
\item \textbf{Simp loops:} Rewriting rules can cycle indefinitely
\item \textbf{Memory exhaustion:} Large expressions overwhelm the elaborator
\end{itemize}

The working approach uses \textbf{targeted lemmas}:
\begin{leancode}
rw [Riemann_trtr]  -- Use pre-proven component value
field_simp [hr0, hf0]
ring_nf
\end{leancode}

This is more verbose but reliable. The session notes document specific instances:
\begin{quote}
``Early in \texttt{Kretschmann\_six\_blocks} Step 3, \texttt{simp}/\texttt{simp\_rw} loops or timeouts occurred due to \texttt{RiemannUp} expansion and AC rewriting. The final working approach avoided generic simp in favor of targeted lemmas plus \texttt{ring\_nf}.''
\end{quote}

\subsection{The Library Mismatch Problem}

\texttt{mathlib} has abstract differential geometry: smooth manifolds, tangent bundles, connections. But it does not have:
\begin{itemize}
\item Explicit Christoffel symbol computation for specific metrics
\item Coordinate-based Riemann tensor calculation
\item Infrastructure for diagonal metrics with symbolic entries
\end{itemize}

The abstract machinery doesn't compute. We needed concrete coordinate calculations, which required building a parallel infrastructure.

\subsection{The Differentiability Overhead}

Every derivative in Lean requires proving the function is differentiable at the point. For the simple function $f(r) = 1 - 2M/r$, we need:
\begin{leancode}
lemma f_differentiableAt (M r : \\mathbb{R}) (hr : r \\neq 0) :
    DifferentiableAt \\mathbb{R} (f M) r := ...

lemma f_hasDerivAt (M r : \\mathbb{R}) (hr : r \\neq 0) :
    HasDerivAt (f M) (2*M/r^2) r := ...

lemma contDiffAt_f (M r : \\mathbb{R}) (hr : r \\neq 0) :
    ContDiffAt \\mathbb{R} 2 (f M) r := ...
\end{leancode}

The $C^2$ smoothness lemma was a critical bottleneck---all six Riemann component proofs were stuck until it was added.

\subsection{The Algebraic Normalization Problem}

The Kretschmann proof requires showing that 256 terms (most zero) collapse to six blocks. This involves:
\begin{itemize}
\item Proving off-diagonal Riemann components vanish (60+ cases)
\item Normalizing weight factors: $g^{aa} g^{bb} g^{aa} g^{bb} = (g^{aa})^2 (g^{bb})^2$
\item Handling Riemann symmetries: $R_{abcd} = -R_{bacd} = -R_{abdc} = R_{cdab}$
\end{itemize}

We added lemmas:
\begin{leancode}
lemma weight_xyxy (x y : \\mathbb{R}) : x * y * x * y = x^2 * y^2 := by ring
lemma weight_xyyx (x y : \\mathbb{R}) : x * y * y * x = x^2 * y^2 := by ring
lemma sixBlock_sq_form ...
lemma sixBlock_sq_form_swap_cd ...
\end{leancode}

On paper: ``by symmetry.'' In Lean: dozens of helper lemmas.

\subsection{Summary: The Formalization Gap}

\begin{center}
\begin{tabular}{lcc}
\toprule
\textbf{Aspect} & \textbf{Paper} & \textbf{Lean} \\
\midrule
Index summation & Implicit & Explicit \texttt{sumIdx} machinery \\
Domain conditions & ``Clearly'' & Threaded hypotheses everywhere \\
Derivatives & Assumed & \texttt{DifferentiableAt} proofs required \\
Simplification & ``By algebra'' & Targeted rewrites + \texttt{ring\_nf} \\
Symmetry & ``By symmetry'' & Explicit antisymmetry lemmas \\
\bottomrule
\end{tabular}
\end{center}

The formalization difficulty is \textbf{orthogonal} to mathematical difficulty. G1 is mathematically trivial but formally hard. G2--G5 would be both mathematically and formally hard.

This gap is a finding in itself: it explains why GR hasn't been formalized before and why the artifact has value.

% ===================================================================
% PART 3: AXIOM CALIBRATION FRAMEWORK
% ===================================================================

\section{Axiom Calibration: An Organizational Methodology}
\label{sec:axcal}

\subsection{Purpose and Scope}

\AxCal{} is an \textbf{organizational methodology} for tracking which foundational axioms are used by different proof routes in physics. It is not:
\begin{itemize}
\item A new foundational system
\item A replacement for reverse mathematics
\item A claim of deep mathematical novelty
\end{itemize}

It applies standard meta-mathematical concepts (from reverse mathematics \cite{Simpson2009}, constructive analysis \cite{BishopBridges1985}, and proof theory) to organize the foundational analysis of GR theorems.

\subsection{The Four Portals}

A proof ``crosses a portal'' when it uses a technique requiring specific axiomatic strength:

\paragraph{Zorn Portal (Choice Axis).} Applies Zorn's lemma to a poset of mathematical objects. Requires Axiom of Choice.

\emph{GR examples:} Maximal extensions (G4), MGHD existence (G2).

\paragraph{Limit-Curve Portal (Compactness Axis).} Invokes Ascoli-Arzel\`a or similar compactness arguments to extract convergent subsequences. Requires Fan Theorem (constructive) or Weak K\"onig's Lemma (classical reverse math).

\emph{GR examples:} Singularity theorems (G3).

\paragraph{Serial-Chain Portal (Choice Axis via DC).} Builds infinite sequences by dependent choice: $x_{n+1}$ depends on $x_0, \ldots, x_n$.

\emph{GR examples:} Some geodesic extension arguments.

\paragraph{Reductio Portal (Logic Axis).} Essential proof by contradiction: assume $\neg P$, derive contradiction, conclude $P$ for non-decidable $P$.

\emph{GR examples:} Singularity theorems (G3), uniqueness proofs (G2).

\subsection{Height Profiles}

An \textbf{AxisProfile} is a triple $(h_{\text{Choice}}, h_{\text{Comp}}, h_{\text{Logic}})$ where each component is 0, 1, or $\omega$:
\begin{itemize}
\item \textbf{Height 0:} No use of the corresponding axiom class
\item \textbf{Height 1:} Uses countable/dependent choice, Fan Theorem, or LEM for $\Sigma_0$ statements
\item \textbf{Height $\omega$:} Essential use at higher cardinalities or impredicative levels
\end{itemize}

\paragraph{Height 0 = Constructive at proof-route level.} A Height 0 proof performs finite symbolic computation, explicit construction, or decidable case analysis. No choice, compactness, or essential contradiction.

\subsection{From Organizational Profiles to Mechanical Audits}

A common objection is that a ``Height 0'' classification can be undercut by the proof assistant's ambient foundations: importing large libraries may silently pull in classical choice or excluded middle even if the \emph{mathematical idea} is constructive. We therefore separate two notions:

\begin{itemize}
\item \textbf{Proof-route height (this paper):} whether the argument crosses any of the four portals (Zorn, compactness, serial-choice, reductio) when written in a standard mathematical style.
\item \textbf{Kernel-level axiom signature (auditable in Lean):} which axioms a particular theorem depends on, as reported by Lean's dependency tracking.
\end{itemize}

Lean supports a concrete audit via \texttt{\#print axioms}. For example, one can ask Lean for the axioms used by a theorem:
\begin{leancode}
#print axioms Papers.P5_GeneralRelativity.Schwarzschild.Ricci_zero_ext
\end{leancode}
In the present artifact, we emphasize the proof-route claim (no high-level portals are needed for G1), and we outline a path to strengthen it into a mechanical axiom signature report as future work (Section~\ref{sec:artifact} records the exact library versions needed for reproducibility).

\subsection{The Five GR Targets}

\begin{center}
\begin{tabular}{llcl}
\toprule
\textbf{Target} & \textbf{Description} & \textbf{Profile} & \textbf{Status} \\
\midrule
G1 & Schwarzschild vacuum & $(0,0,0)$ & \textbf{Formalized} \\
G2 & Cauchy/MGHD existence & $(1,0,1)$ & Paper analysis \\
G3 & Singularity theorems & $(0,1,1)$ & Paper analysis \\
G4 & Maximal extensions & $(1,0,0)$ & Paper analysis \\
G5 & Computable evolution & Fails & Paper analysis \\
\bottomrule
\end{tabular}
\end{center}

\paragraph{G1 is Height 0.} The Schwarzschild vacuum check is finite symbolic computation: derivatives of $f(r) = 1 - 2M/r$, Christoffel formula application, index contraction, algebraic simplification. No portals crossed.

This is \textbf{unsurprising}---nobody would expect a textbook calculation to require Zorn. The value of formalizing G1 is not the Height 0 result itself, but demonstrating that the \AxCal{} tracking machinery works.

\paragraph{G2--G5 are where hidden axioms live.} These require non-trivial foundational commitments:
\begin{itemize}
\item G2: Zorn for maximality, reductio for uniqueness
\item G3: Compactness (limit-curve lemma), reductio (completeness $\Rightarrow$ contradiction)
\item G4: Zorn on extension posets
\item G5: Pour-El-Richards shows computable data can yield non-computable solutions
\end{itemize}

Formalizing these would be the valuable next step.

\subsection{What \AxCal{} Is Not}

\paragraph{Not a claim of novelty for reverse mathematics.} The correspondence between Zorn and AC, between Ascoli-Arzel\`a and WKL$_0$, between reductio and LEM is standard. \AxCal{} repackages these in GR-specific terminology.

\paragraph{Not a claim that Height 0 means ``constructive in Lean.''}  Our Lean formalization uses classical \texttt{mathlib} (with full LEM and choice). The Height 0 claim is about the \emph{proof route}, not the verification infrastructure. This distinction (``structural certification'') is philosophically debatable but organizationally useful.

\paragraph{Not a complete analysis.} The G2--G5 profiles are based on analyzing standard proofs. We do not prove these are \emph{optimal}---alternative proof routes might achieve lower heights.

% ===================================================================
% PART 4: THE FORMALIZATION
% ===================================================================

\section{The Lean 4 Formalization}
\label{sec:formalization}

\subsection{Repository Structure}

The formalization consists of three main files:

\begin{center}
\begin{tabular}{lrl}
\toprule
\textbf{File} & \textbf{Lines} & \textbf{Content} \\
\midrule
\texttt{Schwarzschild.lean} & $\sim$2,300 & Metric, Christoffel symbols, $f$ derivatives \\
\texttt{Riemann.lean} & $\sim$12,400 & Riemann components, Ricci tensor, symmetries \\
\texttt{Invariants.lean} & $\sim$1,300 & Kretschmann scalar, six-block decomposition \\
\bottomrule
\end{tabular}
\end{center}

Supporting files: \texttt{Interfaces.lean} (type definitions), \texttt{Compose.lean} (aggregators), \texttt{Certificates.lean} (\AxCal{} tracking stubs).
\subsection{Artifact and Reproducibility}
\label{sec:artifact}

\begin{mdframed}[style=status]
\noindent\textbf{Repository:} \url{https://github.com/AICardiologist/FoundationRelativity} \\
\textbf{Commit/tag:} \texttt{483dd449fd699ec91296a617295d27f9db161d0f} \\
\textbf{Lean:} \texttt{leanprover/lean4:v4.23.0-rc2} \qquad
\textbf{mathlib:} \texttt{24dd4cacbe11d2535f2537c4a64ab25f72842cee} \\
\textbf{Build:} \texttt{lake build} \qquad
\textbf{No sorries (GR):} \texttt{rg -n "sorry" -g "*.lean" Papers/P5\_GeneralRelativity/GR} \\
\textbf{Machine used for timing:} \texttt{macOS (Darwin 24.3.0, arm64)} \\
\textbf{Clean full-repo build time:} 1h 11m 54s (cold cache, Feb~4~2026) \\
\textbf{GR target build time:} 2m 10s for \texttt{Papers.P5\_GeneralRelativity.GR.Riemann} (warm cache, first target build) \\
\textbf{Incremental GR rebuild:} 4.17s (warm cache, no source changes, Feb~4~2026)
\end{mdframed}

The development is a standard Lean~4/\texttt{mathlib} project. From the repository root, the following commands should reproduce the main results:
\begin{leancode}
lake build
\end{leancode}
and (optionally) run a focused build of the GR modules:
\begin{leancode}
lake build Papers.P5_GeneralRelativity.GR.Schwarzschild
lake build Papers.P5_GeneralRelativity.GR.Riemann
lake build Papers.P5_GeneralRelativity.GR.Invariants
\end{leancode}

Exact versions are pinned in \texttt{lean-toolchain} and \texttt{lake-manifest.json} at the repository root; those files should be treated as authoritative for reproduction.


\subsection{Key Definitions}

\paragraph{Index type.}
\begin{leancode}
inductive Idx | t | r | \\theta | \\phi
  deriving DecidableEq, Fintype
\end{leancode}

\paragraph{Metric and inverse.}
\begin{leancode}
noncomputable def g (M : \\mathbb{R}) : Idx \\to Idx \\to \\mathbb{R} \\to \\mathbb{R} \\to \\mathbb{R}
| Idx.t, Idx.t, r, _ => -(f M r)
| Idx.r, Idx.r, r, _ => (f M r)^-1
| Idx.\\theta, Idx.\\theta, r, _ => r^2
| Idx.\\phi, Idx.\\phi, r, theta => r^2 * (Real.sin theta)^2
| _, _, _, _ => 0
\end{leancode}

\paragraph{Christoffel aggregator.}
\begin{leancode}
noncomputable def \\Gammatot (M : \\mathbb{R}) : Idx \\to Idx \\to Idx \\to \\mathbb{R} \\to \\mathbb{R} \\to \\mathbb{R}
| Idx.t, Idx.t, Idx.r, r, _ => M / (r^2 * f M r)
| Idx.r, Idx.t, Idx.t, r, _ => M * f M r / r^2
-- ... 9 non-zero cases ...
| _, _, _, _, _ => 0
\end{leancode}

\subsection{Main Theorems}

\paragraph{Vacuum equations.}
\begin{leancode}
theorem Ricci_zero_ext (M r \\theta : \\mathbb{R}) (h_ext : Exterior M r \\theta) (h_sin_nz : Real.sin \\theta \\neq 0) :
    \\forall a b, RicciContraction M r \\theta a b = 0
\end{leancode}

\paragraph{Kretschmann invariant.}
\begin{leancode}
theorem Kretschmann_exterior_value (M r \\theta : \\mathbb{R}) (hM : 0 < M) (hr : 2*M < r) (h\\theta : 0 < \\theta \\land \\theta < Real.pi) :
    Kretschmann M r \\theta = 48 * M^2 / r^6
\end{leancode}

\subsection{Technique Highlights from the Code}

This section records a few concrete patterns that repeatedly improved proof stability and build time.

\paragraph{Package the exterior domain.}
Many theorems are naturally phrased on the exterior region $r>2M$, where one immediately needs $r\neq 0$ and $f(M,r)\neq 0$ for denominator clearing. The code packages these hypotheses in an \texttt{Exterior} predicate and derives reusable nonvanishing lemmas (\texttt{r\_ne\_zero}, \texttt{f\_ne\_zero}). The $0<\theta<\pi$ side-condition is tracked separately and used only to obtain $\sin\theta\neq 0$ for the inverse $\varphi\varphi$ component.

\paragraph{Expand finite index sums explicitly.}
The decisive move is to make every finite sum over indices reducible to a fixed normal form (e.g.\ a 4-term or 16-term expansion) before attempting algebra. For example:
\begin{leancode}
rw [sumIdx2_expand]   -- expand \\sum \\mu \\sum \\nu into 16 concrete terms
\end{leancode}
This makes later \texttt{simp} calls predictable and avoids divergence from exploratory rewriting.

\paragraph{Use controlled simplification (\texttt{simp only}) with ``vanishing lemma libraries.''}
The Kretschmann contraction naively expands to 256 terms. The code first expands sums, then eliminates the vast majority of terms using an explicit lemma set stating that off-block Riemann components are zero in this chart. A representative proof step looks like:
\begin{leancode}
simp only [Riemann_last_equal_zero,
  R_tr_t\\theta_zero, R_tr_t\\phi_zero,  -- (many more)
  ...]
\end{leancode}
The guiding principle is to keep the simp set \emph{small and explicit} so that normalization is fast and stable across \texttt{mathlib} upgrades.

\paragraph{Exploit diagonal structure via a six-block identity.}
Once indices are raised with a diagonal inverse metric, the Kretschmann scalar collapses to six unordered index pairs. The artifact proves a structural lemma:
\begin{leancode}
lemma Kretschmann_six_blocks
    (M r \\theta : \\mathbb{R}) (h_ext : Exterior M r \\theta) (h\\theta : Real.sin \\theta \\neq 0) :
    Kretschmann M r \\theta = 4 * sumSixBlocks M r \\theta := by
  classical
  -- expand to 256 terms, kill 232 by simp-only, regroup into 6 blocks
  ...
\end{leancode}
This is the main reason the final invariant computation is tractable.

\paragraph{Case-split intentionally, not accidentally.}
For results like $R_{\mu\nu}=0$, the proof explicitly performs a $4\times 4$ case split and handles off-diagonal cases by local simplification:
\begin{leancode}
cases a <;> cases b
-- 16 cases: 12 off-diagonal simp-outs + 4 diagonal cancellations
\end{leancode}
While inelegant on paper, this is robust in a proof assistant and makes failure modes localized.

\subsection{Proof Sketch and File Roles}

\paragraph{File roles.}
\begin{itemize}
\item \texttt{Schwarzschild.lean}: defines the Schwarzschild metric $g$, its inverse $g^{-1}$, and the nonzero Christoffel symbols $\Gamma^a_{bc}$ (collected in \texttt{\\Gammatot}). It proves the required derivative lemmas for $f(r)=1-\frac{2M}{r}$ and the basic smoothness facts on the exterior domain.
\item \texttt{Riemann.lean}: defines the Riemann tensor by the standard coordinate formula
\[
R^{\rho}{}_{\sigma\mu\nu}=\partial_{\mu}\Gamma^{\rho}{}_{\sigma\nu}-\partial_{\nu}\Gamma^{\rho}{}_{\sigma\mu}
\;+\;\Gamma^{\rho}{}_{\lambda\mu}\Gamma^{\lambda}{}_{\sigma\nu}-\Gamma^{\rho}{}_{\lambda\nu}\Gamma^{\lambda}{}_{\sigma\mu},
\]
proves its symmetries, evaluates all nonzero components, and shows the Ricci tensor $R_{\mu\nu}=R^{\alpha}{}_{\mu\alpha\nu}$ vanishes.
\item \texttt{Invariants.lean}: defines the Kretschmann scalar $K=R_{abcd}R^{abcd}$, proves the six-block decomposition using Riemann symmetries, and performs the final algebraic reduction to $48M^2/r^6$.
\end{itemize}

\paragraph{Key internal lemmas (selected).}
\begin{itemize}
\item \texttt{sumIdx}, \texttt{sumIdx\_expand}, \texttt{sumIdx\_mul\_sumIdx\_swap}: finite-index summation machinery and Fubini-style reordering.
\item \texttt{\\Gammatot\_symm}, \texttt{g\_symm}: symmetry lemmas for Christoffel and metric components.
\item \texttt{Riemann\_via\_Gamma1}: the core identity rewriting $R_{\beta a r \theta}$ in terms of $\partial \Gamma_1$ and $\Gamma\Gamma$ terms.
\item \texttt{R\_tr\_**\_zero} family: systematic vanishing of off-diagonal components.
\item \texttt{sixBlock} family: reduces 256-term Kretschmann sum to six weighted blocks.
\end{itemize}

\paragraph{Lean tactic patterns.}
The working proofs rely on short, reliable algebraic pipelines:
\begin{itemize}
\item \texttt{simp only} with explicit lemma lists (to avoid simp loops)
\item \texttt{simp\_rw} for controlled rewriting of sumIdx/\\Gammatot expansions
\item \texttt{field\_simp} to clear denominators in $f(r)^{-1}$ and $r^{-2}$
\item \texttt{ring\_nf} or \texttt{abel} for normalization and cancellation
\end{itemize}

\paragraph{Dependency diagram (key lemmas and files).}
\begin{figure}[h]
\centering
\begin{Verbatim}[fontsize=\small]
Interfaces.lean --+
Compose.lean    --+--> Schwarzschild.lean --> Riemann.lean --> Invariants.lean
Certificates.lean-+        |                    |                  |
  (AxCal stubs)            |                    |                  |
                           v                    v                  v
                    \\Gammatot, g, f-derivs  Riemann_via_Gamma1, R_*_zero  sixBlock, Kretschmann_value
\end{Verbatim}
\caption{High-level dependency flow. Core lemmas in each file feed the next stage of the Schwarzschild pipeline.}
\end{figure}

\paragraph{Human-readable proof sketch (G1).}
The Lean proof follows the textbook pipeline but makes every hypothesis explicit (e.g., $r>2M$ and $0<\theta<\pi$) and every cancellation justified.
\begin{enumerate}
\item \textbf{Domain and metric.} Fix the exterior region $r>2M$ with $0<\theta<\pi$. Define the Schwarzschild metric in Schwarzschild coordinates:
\[
g_{tt}=-(1-\tfrac{2M}{r}),\quad g_{rr}=(1-\tfrac{2M}{r})^{-1},\quad g_{\theta\theta}=r^2,\quad g_{\phi\phi}=r^2\sin^2\theta.
\]
Lean also defines $g^{-1}$ explicitly and proves $g^{-1}g=\mathrm{Id}$ componentwise under $r\neq 0$ and $\sin\theta\neq 0$.
\item \textbf{Christoffel symbols.} Use the coordinate formula for $\Gamma^a_{bc}$ and a case split over indices to show only the standard nine symbols are nonzero. In the exterior region with $f(r)=1-\frac{2M}{r}$, the nonzero symbols are:
\[
\Gamma^t_{tr}=\Gamma^t_{rt}=\frac{M}{r^2 f},\quad
\Gamma^r_{tt}=\frac{M f}{r^2},\quad
\Gamma^r_{rr}=-\frac{M}{r^2 f},
\]
\[
\Gamma^r_{\theta\theta}=-(r-2M),\quad
\Gamma^r_{\phi\phi}=-(r-2M)\sin^2\theta,\quad
\Gamma^\theta_{r\theta}=\Gamma^\theta_{\theta r}=\frac{1}{r},
\]
\[
\Gamma^\theta_{\phi\phi}=-\sin\theta\cos\theta,\quad
\Gamma^\phi_{r\phi}=\Gamma^\phi_{\phi r}=\frac{1}{r},\quad
\Gamma^\phi_{\theta\phi}=\Gamma^\phi_{\phi\theta}=\cot\theta.
\]
Lean proves these closed forms and their derivatives (e.g., $\partial_r f$ and $\partial_\theta\sin^2\theta$) with explicit differentiability lemmas on the exterior domain.
\item \textbf{Riemann tensor.} Define $R^\rho{}_{\sigma\mu\nu}$ by the coordinate formula above. Expand each nonzero component with the \texttt{\\Gammatot} aggregator, use symmetry identities
$R_{abcd}=-R_{bacd}=-R_{abdc}=R_{cdab}$, and show all off-diagonal components vanish by case analysis.
\item \textbf{Ricci tensor.} Contract indices to form $R_{\mu\nu}$. Each diagonal component is a finite sum of nonzero terms that cancel; Lean proves these cancellations by explicit rewriting and algebraic normalization (\texttt{ring\_nf}, \texttt{field\_simp}).
\item \textbf{Kretschmann scalar.} Expand $K=R_{abcd}R^{abcd}$ as a finite sum over $4^4=256$ index combinations. Using Riemann symmetries and vanishing components, the sum collapses to six independent blocks (\texttt{sixBlock}). Each block is evaluated and the weighted sum reduces to $48M^2/r^6$.
\end{enumerate}

\paragraph{Comparison with \emph{Gravitation} (MTW).}
MTW (and Wald/Carroll) present essentially the same coordinate computation, but at a narrative level: many cancellations are asserted by symmetry or ``by inspection,'' and domain hypotheses (e.g., $\sin\theta\neq 0$ or $r\neq 0$) are implicit. Lean forces every derivative, index contraction, and algebraic simplification to be explicit, and it surfaces which hypotheses are actually required. The formalization therefore mirrors MTW's flow but replaces informal steps with explicit, mechanically checked reductions.

\paragraph{Novelty and limits.}
There is no new physics here: the Schwarzschild vacuum check and Kretschmann invariant are textbook results. The novelty is methodological: (i) a complete, checkable proof in Lean 4, (ii) a detailed map of the proof's dependency structure, and (iii) a reusable infrastructure for future GR formalizations (e.g., alternative metrics or coordinate systems). The exercise highlights how ``easy'' GR calculations hide a large amount of formal bookkeeping.

\paragraph{Axioms and reverse-math perspective.}
At the level of mathematical content, the proof is \emph{Height 0}: it is a finite symbolic computation with no need for choice, compactness, or non-constructive existence arguments. That said, the current Lean development sits inside mathlib's classical environment, which assumes classical logic and standard real analysis facts (e.g., completeness of $\mathbb{R}$). The project therefore does not claim a fully constructive foundation; instead it identifies which axioms are actually \emph{used} in the GR pipeline. The formalization also makes hidden hypotheses explicit (e.g., $r\neq 0$, $\sin\theta\neq 0$, $f(r)\neq 0$), clarifying the minimal domain required for each step.

\subsection{What Is Verified (and What Is Not)}

\paragraph{Verified.} The Lean development verifies the Schwarzschild vacuum calculation in a single coordinate patch: explicit Christoffel symbols, all Riemann components, vanishing Ricci tensor, and the Kretschmann scalar in the exterior region $r>2M$ with $0<\theta<\pi$.

\paragraph{Not verified.} This does \emph{not} prove the full Einstein field equations or global properties of the spacetime, nor does it formalize coordinate changes, maximal extensions, or causal structure. It is a formal check of a standard coordinate computation, not a complete GR formalization.

\subsection{Build Status}

As of February 2026:
\begin{itemize}
\item \texttt{lake build Papers.P5\_GeneralRelativity.GR.Invariants}: \textbf{Success}
\item \texttt{lake build Papers.P5\_GeneralRelativity.GR.Riemann}: \textbf{Success}
\item \texttt{rg --glob '*.lean' -n '\textbackslash bsorry\textbackslash b' Papers/P5\_GeneralRelativity/GR}: \textbf{No results}
\item Builds should be run from the project root (the directory containing \texttt{lakefile.lean}).
\end{itemize}

Zero errors, zero sorries in the GR folder. (There remain lint warnings such as \texttt{unnecessarySimpa} and \texttt{unusedSimpArgs}; these do not affect correctness but indicate cleanup opportunities.)

% ===================================================================
% PART 5: MULTI-AI WORKFLOW
% ===================================================================

\section{Multi-AI Agent Collaboration}
\label{sec:ai}

This project was produced by four AI agents under human direction over roughly six months of active development (April--October 2025).

\subsection{Agent Roles}

\paragraph{Claude Code (Opus 4.5).} Primary implementation and tactical coding.
\begin{itemize}
\item Repository setup, namespace organization, CI/CD
\item Index type design (\texttt{Idx}, \texttt{sumIdx}, \texttt{\\Gammatot})
\item Refactoring when early approaches hit complexity walls
\item Build system maintenance across \texttt{mathlib} updates
\end{itemize}

\paragraph{GPT-5.2.} Mathematical strategy and theorem formulation.
\begin{itemize}
\item Theorem formulation with minimal dependency choices
\item Proof strategy for bottleneck identities
\item Tactic selection and algebraic normalization guidance
\item Key breakthrough: identified need for $C^2$ smoothness lemma
\end{itemize}

\paragraph{Gemini 2.5 Pro Deep Think (Google).} Strategic guidance.
\begin{itemize}
\item Theorem formulation: minimal dependency choices
\item Kretschmann six-block strategy: reduce 256 terms to 6
\item Literature correlation: mapping to MTW chapters
\item \AxCal{} framework validation
\end{itemize}

\paragraph{GPT-5.2 Codex (late-stage).} Code cleanup and refactoring.
\begin{itemize}
\item Lint-driven cleanup (unused simp arguments, unreachable tactics)
\item Simplification of differentiability lemmas and helper proofs
\item Paper edits to reflect build status and workflow
\end{itemize}

\subsection{Trust Boundary: AI as Proposer, Lean as Verifier}

A critical discipline in the workflow was maintaining a strict trust boundary: AI systems were used to propose lemmas, decompositions, and proof strategies, but \emph{never} as sources of mathematical authority. Every claim was required to pass Lean's kernel; hallucinated lemmas were treated as search noise. In practice, this meant (i) preferring small local lemmas over monolithic automation, (ii) keeping simp/rewrite sets explicit, and (iii) using the prover to enforce all domain side-conditions (nonvanishing denominators, $\sin\theta\neq 0$, etc.).

\subsection{Human Role}

\begin{enumerate}
\item \textbf{Goal setting:} Defined G1--G5 targets and \AxCal{} framework
\item \textbf{Agent coordination:} Directed which AI handled which task
\item \textbf{Quality control:} Reviewed all AI-generated code for correctness, clarity, maintainability
\end{enumerate}

\subsection{Lessons Learned}

\paragraph{What worked:}
\begin{itemize}
\item Specialization: Different agents have different strengths
\item Iteration: Multiple rounds of generation/review/refinement
\item Documentation: Agents document their own reasoning
\end{itemize}

\paragraph{What didn't work:}
\begin{itemize}
\item Aggressive automation (\texttt{simp} explosions)
\item Assuming \texttt{mathlib} has what you need (it often doesn't)
\item Large monolithic proofs (need to break into lemmas)
\end{itemize}

% ===================================================================
% PART 6: LIMITATIONS AND FUTURE WORK
% ===================================================================

\section{Limitations and Future Work}
\label{sec:limitations}

\subsection{What We Did Not Prove}

\begin{itemize}
\item \textbf{Behavior at $r = 2M$:} The event horizon is a coordinate singularity. Extending to Kruskal-Szekeres coordinates would require additional formalization.

\item \textbf{Behavior at poles $\theta = 0, \pi$:} Coordinate singularity in spherical coordinates. Extending would require stereographic patch.

\item \textbf{Global structure:} We work in a single coordinate chart. Full manifold theory with atlas, transition functions, coordinate-independent tensors is not formalized.

\item \textbf{G2--G5:} The interesting cases with hidden axioms are paper-level analysis only.
\end{itemize}

\subsection{Future Directions}

\paragraph{Short-term (builds on current work):}
\begin{enumerate}
\item Add stereographic coordinate patch for poles
\item Prove coordinate transformations preserve curvature
\item Extend to Reissner-Nordstr\"om (charged), Kerr (rotating)
\end{enumerate}

\paragraph{Medium-term (substantial new work):}
\begin{enumerate}
\item Formalize Kruskal-Szekeres coordinates, prove regularity at horizon
\item Formalize Cauchy problem (G2)---local PDE well-posedness
\item Build manifold atlas machinery
\end{enumerate}

\paragraph{Long-term (research-level):}
\begin{enumerate}
\item Formalize singularity theorems (G3)---requires global causal structure
\item Formalize Pour-El-Richards (G5)---requires computability theory in Lean
\item Prove height profiles are \emph{optimal} (no lower-height proof exists)
\end{enumerate}

\section{Conclusion}

We have presented a fully machine-checked verification of Schwarzschild curvature calculations in Lean 4. The formalization demonstrates that formal GR is feasible, documents why ``trivial'' mathematics is hard to formalize, and provides infrastructure for future work.

The \AxCal{} framework offers an organizational methodology for tracking axiomatic dependencies in physics. While the Height 0 result for G1 is unsurprising, the framework is positioned for application to G2--G5, where hidden axioms actually appear.

The multi-AI agent workflow (Claude Code Opus 4.5, GPT-5.2, Gemini 2.5 Pro Deep Think, GPT-5.2 Codex) represents a case study in AI-assisted theorem proving, showing how different AI strengths complement each other.

The value of this work is the \emph{artifact} and the \emph{program} it initiates, not new mathematics. We have demonstrated feasibility and provided a foundation for more ambitious formalizations of General Relativity.

\section*{Acknowledgments}

The author thanks the AI agents (Claude Code Opus 4.5, GPT-5.2, Gemini 2.5 Pro Deep Think, GPT-5.2 Codex) for their contributions to the formalization. All errors remain the author's responsibility.

\bibliographystyle{plain}
\bibliography{../references}

\end{document}
