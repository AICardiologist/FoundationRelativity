\documentclass[11pt]{article}

% -------------------------------------------------
% Preamble
% -------------------------------------------------
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\IfFileExists{lmodern.sty}{\usepackage{lmodern}}{}
\usepackage{geometry}
\geometry{margin=1in}

\usepackage{amsmath,amssymb}
\usepackage{amsthm}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue}
\usepackage{xcolor}
\usepackage{booktabs}

% mdframed with fallback
\IfFileExists{mdframed.sty}{
  \usepackage{mdframed}
  \mdfdefinestyle{status}{backgroundcolor=gray!10,linecolor=gray!60!black,linewidth=0.8pt,
    innerleftmargin=6pt,innerrightmargin=6pt,innertopmargin=4pt,innerbottommargin=4pt}
}{
  \newenvironment{mdframed}[1][]{\begin{quote}\itshape}{\end{quote}}
}

% Code formatting - using fancyvrb for Unicode support
\usepackage{fancyvrb}
\DefineVerbatimEnvironment{leancode}{Verbatim}{fontsize=\small,commandchars=\\\{\}}

% -------------------------------------------------
% Theorem styles
% -------------------------------------------------
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% -------------------------------------------------
% Macros
% -------------------------------------------------
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\AxCal}{\textsc{AxCal}}
\newcommand{\Christoffel}[3]{\Gamma^{#1}_{#2#3}}
\newcommand{\Riemann}[4]{R^{#1}_{#2#3#4}}
\newcommand{\Ricci}[2]{R_{#1#2}}

% -------------------------------------------------
% Title
% -------------------------------------------------
\title{Formalizing Schwarzschild Spacetime in Lean 4:\\
A First Complete Verification of General Relativistic Curvature\\
and a Methodology for Tracking Axiomatic Dependencies}

\author{Paul Chun--Kit Lee\\
\texttt{dr.paul.c.lee@gmail.com}\\
New York University, NY}

\date{February 2026}

\begin{document}
\maketitle

\begin{abstract}
We present the first complete formal verification of Schwarzschild curvature calculations in a proof assistant, comprising approximately 16,000 lines of Lean 4 code. The formalization verifies the full pipeline from metric definition through Christoffel symbols, Riemann tensor components, Ricci tensor vanishing, and Kretschmann invariant ($K = 48M^2/r^6$) in the exterior region ($r > 2M$). Despite the underlying mathematics being textbook material, the formalization required six months and four collaborating AI agents (Claude Code Opus 4.5, GPT-5.2, Gemini 2.5 Pro Deep Think, GPT-5.2 Codex), revealing a significant gap between informal and formal mathematical practice.

We introduce \emph{Axiom Calibration} (\AxCal{}), an organizational methodology for tracking which foundational axioms (choice, compactness, classical logic) are required by different proof routes in physics. The formalization structurally certifies that the Schwarzschild vacuum verification is ``Height 0''---requiring no Axiom of Choice, compactness arguments, or essential proof by contradiction---a result that is expected but now machine-verified. We analyze four additional GR targets (Cauchy problem, singularity theorems, maximal extensions, computable evolution) at the paper level, identifying where non-constructive axioms enter standard proofs.

The primary contributions are: (1) the artifact itself, demonstrating feasibility of formal GR verification; (2) documentation of why ``trivial'' mathematics is surprisingly hard to formalize; (3) a multi-AI agent workflow as a case study in AI-assisted theorem proving; and (4) the \AxCal{} framework as a tool for organizing foundational analysis of physics theorems.

\medskip
\noindent\textbf{Artifact:} 16,000 lines Lean 4 | \textbf{Build time:} $<$30 seconds | \textbf{Status:} Zero errors, zero sorries in the GR folder (lint warnings remain)
\end{abstract}

\begin{mdframed}[backgroundcolor=gray!10, linewidth=0pt]
\textbf{Scope and Honest Claims}

This paper reports on \emph{engineering} and \emph{methodology}, not new mathematics or physics. The Schwarzschild calculations we verify are standard textbook material \cite{Wald1984,MTW1973,Carroll2004}. The verification that these calculations are ``Height 0'' (constructive at the proof-route level) is unsurprising---they are finite symbolic computations.

The value lies in:
\begin{itemize}
\item Demonstrating that formal GR is feasible in Lean 4
\item Documenting the obstacles that made it difficult
\item Providing infrastructure for future, more ambitious formalizations
\item Introducing \AxCal{} as organizational methodology (not foundational breakthrough)
\end{itemize}

The more interesting GR results (G2--G5) are analyzed at the paper level but \emph{not formalized}. Their axiomatic profiles are asserted based on standard proof analysis, not machine-verified.
\end{mdframed}

\tableofcontents
\newpage

% ===================================================================
% PART 1: INTRODUCTION AND MOTIVATION
% ===================================================================

\section{Introduction}
\label{sec:intro}

\subsection{What This Paper Is (And Is Not)}

This paper reports on the first complete formal verification of Schwarzschild spacetime curvature calculations in any proof assistant. We verify the standard textbook pipeline:
\begin{center}
Schwarzschild metric $\to$ Christoffel symbols $\to$ Riemann tensor $\to$ Ricci tensor $\to$ Kretschmann scalar
\end{center}
in Lean 4, with approximately 16,000 lines of code that builds without errors or \texttt{sorry} placeholders on the critical path.

\paragraph{What this paper is:}
\begin{itemize}
\item A \textbf{technique paper} demonstrating feasibility of formal GR verification
\item A \textbf{case study} in multi-AI agent collaboration for theorem proving
\item An \textbf{organizational framework} (\AxCal{}) for tracking axiomatic dependencies in physics
\item \textbf{Documentation} of why formalizing ``trivial'' mathematics is hard
\end{itemize}

\paragraph{What this paper is not:}
\begin{itemize}
\item New mathematics (the Schwarzschild calculations are 100+ years old)
\item New physics (we verify known results, not discover new ones)
\item A foundational breakthrough (the \AxCal{} framework applies known meta-mathematics)
\item Complete GR formalization (we handle only one solution in one coordinate patch)
\end{itemize}

\paragraph{Author context.}
The author is a practicing physician (interventional cardiology) with interests in formal methods and mathematical physics, but no professional training in either field. This project was undertaken as an exercise in learning Lean 4 and exploring the feasibility of formal verification in physics. Readers should evaluate the artifact on its technical merits; domain experts may find opportunities for improvement that a non-specialist would miss.

\subsection{Motivation: Searching for Hidden Axioms}

The original motivation for this project was foundational: \emph{What axioms does General Relativity actually require?}

Standard GR textbooks use the Axiom of Choice (via Zorn's lemma), compactness arguments (Ascoli-Arzel\`a), and proof by contradiction without flagging these as philosophically significant. For a constructive mathematician or a reverse mathematician, these hidden dependencies matter.

We sought to make them explicit by:
\begin{enumerate}
\item Formalizing GR results in a proof assistant
\item Tracking which axiom ``portals'' each proof crosses
\item Assigning ``height'' profiles measuring axiomatic strength
\end{enumerate}

\paragraph{The irony.} We formalized the \emph{easiest} case first: the Schwarzschild vacuum check (G1). This calculation has \textbf{no hidden axioms}---it is finite symbolic computation, obviously constructive. The ``discovery'' that G1 is Height 0 is tautological.

The interesting cases---where hidden axioms actually appear---are:
\begin{itemize}
\item \textbf{G2 (Cauchy problem/MGHD):} Zorn's lemma for maximality
\item \textbf{G3 (Singularity theorems):} Compactness + proof by contradiction
\item \textbf{G4 (Maximal extensions):} Zorn's lemma
\item \textbf{G5 (Computable evolution):} Pour-El--Richards \cite{PourElRichards1989} shows this \emph{fails}
\end{itemize}

These are analyzed at the paper level but \textbf{not formalized}. Formalizing them would be dramatically harder and remains future work.

\subsection{Why Bother Formalizing the Easy Case?}

If G1 has no hidden axioms, why spend six months formalizing it?

\begin{enumerate}
\item \textbf{Proof of concept:} Before attempting G2--G5, we needed to know that formal GR is feasible at all. Schwarzschild establishes the infrastructure.

\item \textbf{The gap is informative:} The difficulty of formalizing G1 reveals how much implicit reasoning standard mathematics employs. This gap is itself a finding.

\item \textbf{Infrastructure for future work:} The tensor calculus machinery (index types, summation helpers, differentiability lemmas) built for G1 transfers to other spacetimes.

\item \textbf{First of its kind:} No prior complete formalization of GR curvature calculations exists in any proof assistant. Being first has value even for routine mathematics.
\end{enumerate}

\subsection{Paper Contributions}

\begin{enumerate}
\item \textbf{Artifact:} First complete Lean 4 formalization of Schwarzschild curvature (Christoffel $\to$ Riemann $\to$ Ricci $\to$ Kretschmann). Zero errors, zero sorries in the GR folder. ~16,000 lines.

\item \textbf{Difficulty Analysis:} Documentation of why ``trivial'' GR calculations require 16,000 lines and 6 months. The gap between informal and formal mathematics is larger than expected.

\item \textbf{\AxCal{} Methodology:} An organizational framework for tracking axiom usage in physics proofs, with four ``portals'' (Zorn, limit-curve, serial-chain, reductio) and three-axis height profiles.

\item \textbf{Multi-AI Workflow:} Case study of Claude Code (Opus 4.5) + GPT-5.2 + Gemini 2.5 Pro Deep Think + GPT-5.2 Codex collaboration, documenting how different AI strengths complement each other.

\item \textbf{Roadmap:} Analysis of G2--G5 at the paper level, providing targets for future formalization.
\end{enumerate}

% ===================================================================
% PART 2: WHY FORMALIZATION IS HARD
% ===================================================================

\section{Why ``Trivial'' Mathematics Is Hard to Formalize}
\label{sec:difficulty}

The Schwarzschild vacuum check is a textbook calculation that any GR graduate student can do by hand in an afternoon. Yet formalizing it required:
\begin{itemize}
\item 16,000 lines of Lean 4 code
\item 6 months of development
\item 3 collaborating AI agents
\item Numerous false starts and refactorings
\end{itemize}

This section documents why.

\subsection{The Index Machinery Problem}

\paragraph{On paper:} Write $\Gamma^\alpha_{\mu\nu}$ and everyone understands.

\paragraph{In Lean:} We must define:
\begin{itemize}
\item An \texttt{Idx} inductive type with constructors \texttt{t}, \texttt{r}, \texttt{$\theta$}, \texttt{$\varphi$}
\item A \texttt{sumIdx} function implementing $\sum_{\mu}$ over this finite type
\item Expansion lemmas showing $\texttt{sumIdx}~f = f(t) + f(r) + f(\theta) + f(\varphi)$
\item Normalization lemmas for rearranging sums
\end{itemize}

The Kretschmann scalar involves $R_{abcd} R^{abcd}$---a sum over $4^4 = 256$ index combinations. Managing this requires:
\begin{itemize}
\item \texttt{sumIdx2\_expand} for double sums
\item \texttt{sixBlock} decomposition exploiting Riemann symmetries
\item Weight normalization lemmas (\texttt{weight\_xyxy}, \texttt{weight\_xyyx}, etc.)
\end{itemize}

None of this exists in \texttt{mathlib}. We built it from scratch.

\subsection{The Side Condition Problem}

\paragraph{On paper:} ``Clearly $r \neq 2M$ and $\sin\theta \neq 0$.''

\paragraph{In Lean:} Every division requires a proof. The expression $f(r)^{-1}$ where $f(r) = 1 - 2M/r$ demands:
\begin{leancode}
hf : f M r != 0
\end{leancode}

This hypothesis must be threaded through \emph{every lemma} that involves the metric. The \texttt{Exterior M r $\theta$} predicate bundles the domain conditions:
\begin{leancode}
structure Exterior (M r theta : Real) : Prop where
  hM : 0 < M
  hr : 2 * M < r
  hTheta : 0 < theta and theta < Real.pi
\end{leancode}

Every Christoffel lemma, every Riemann component, every Ricci contraction carries this predicate as a hypothesis. The overhead is substantial.

\subsection{The Tactic Fragility Problem}

Early proof attempts used aggressive automation:
\begin{leancode}
simp [Riemann, Christoffel, g, gInv, f, ...]
\end{leancode}

This caused:
\begin{itemize}
\item \textbf{Timeouts:} Expanding all definitions creates expressions with thousands of terms
\item \textbf{Simp loops:} Rewriting rules can cycle indefinitely
\item \textbf{Memory exhaustion:} Large expressions overwhelm the elaborator
\end{itemize}

The working approach uses \textbf{targeted lemmas}:
\begin{leancode}
rw [Riemann_trtr]  -- Use pre-proven component value
field_simp [hr0, hf0]
ring_nf
\end{leancode}

This is more verbose but reliable. The session notes document specific instances:
\begin{quote}
``Early in \texttt{Kretschmann\_six\_blocks} Step 3, \texttt{simp}/\texttt{simp\_rw} loops or timeouts occurred due to \texttt{RiemannUp} expansion and AC rewriting. The final working approach avoided generic simp in favor of targeted lemmas plus \texttt{ring\_nf}.''
\end{quote}

\subsection{The Library Mismatch Problem}

\texttt{mathlib} has abstract differential geometry: smooth manifolds, tangent bundles, connections. But it does not have:
\begin{itemize}
\item Explicit Christoffel symbol computation for specific metrics
\item Coordinate-based Riemann tensor calculation
\item Infrastructure for diagonal metrics with symbolic entries
\end{itemize}

The abstract machinery doesn't compute. We needed concrete coordinate calculations, which required building a parallel infrastructure.

\subsection{The Differentiability Overhead}

Every derivative in Lean requires proving the function is differentiable at the point. For the simple function $f(r) = 1 - 2M/r$, we need:
\begin{leancode}
lemma f_differentiableAt (M r : Real) (hr : r != 0) :
    DifferentiableAt Real (f M) r := ...

lemma f_hasDerivAt (M r : Real) (hr : r != 0) :
    HasDerivAt (f M) (2*M/r^2) r := ...

lemma contDiffAt_f (M r : Real) (hr : r != 0) :
    ContDiffAt Real 2 (f M) r := ...
\end{leancode}

The $C^2$ smoothness lemma was a critical bottleneck---all six Riemann component proofs were stuck until it was added.

\subsection{The Algebraic Normalization Problem}

The Kretschmann proof requires showing that 256 terms (most zero) collapse to six blocks. This involves:
\begin{itemize}
\item Proving off-diagonal Riemann components vanish (60+ cases)
\item Normalizing weight factors: $g^{aa} g^{bb} g^{aa} g^{bb} = (g^{aa})^2 (g^{bb})^2$
\item Handling Riemann symmetries: $R_{abcd} = -R_{bacd} = -R_{abdc} = R_{cdab}$
\end{itemize}

We added lemmas:
\begin{leancode}
lemma weight_xyxy (x y : Real) : x * y * x * y = x^2 * y^2 := by ring
lemma weight_xyyx (x y : Real) : x * y * y * x = x^2 * y^2 := by ring
lemma sixBlock_sq_form ...
lemma sixBlock_sq_form_swap_cd ...
\end{leancode}

On paper: ``by symmetry.'' In Lean: dozens of helper lemmas.

\subsection{Summary: The Formalization Gap}

\begin{center}
\begin{tabular}{lcc}
\toprule
\textbf{Aspect} & \textbf{Paper} & \textbf{Lean} \\
\midrule
Index summation & Implicit & Explicit \texttt{sumIdx} machinery \\
Domain conditions & ``Clearly'' & Threaded hypotheses everywhere \\
Derivatives & Assumed & \texttt{DifferentiableAt} proofs required \\
Simplification & ``By algebra'' & Targeted rewrites + \texttt{ring\_nf} \\
Symmetry & ``By symmetry'' & Explicit antisymmetry lemmas \\
\bottomrule
\end{tabular}
\end{center}

The formalization difficulty is \textbf{orthogonal} to mathematical difficulty. G1 is mathematically trivial but formally hard. G2--G5 would be both mathematically and formally hard.

This gap is a finding in itself: it explains why GR hasn't been formalized before and why the artifact has value.

% ===================================================================
% PART 3: AXIOM CALIBRATION FRAMEWORK
% ===================================================================

\section{Axiom Calibration: An Organizational Methodology}
\label{sec:axcal}

\subsection{Purpose and Scope}

\AxCal{} is an \textbf{organizational methodology} for tracking which foundational axioms are used by different proof routes in physics. It is not:
\begin{itemize}
\item A new foundational system
\item A replacement for reverse mathematics
\item A claim of deep mathematical novelty
\end{itemize}

It applies standard meta-mathematical concepts (from reverse mathematics \cite{Simpson2009}, constructive analysis \cite{BishopBridges1985}, and proof theory) to organize the foundational analysis of GR theorems.

\subsection{The Four Portals}

A proof ``crosses a portal'' when it uses a technique requiring specific axiomatic strength:

\paragraph{Zorn Portal (Choice Axis).} Applies Zorn's lemma to a poset of mathematical objects. Requires Axiom of Choice.

\emph{GR examples:} Maximal extensions (G4), MGHD existence (G2).

\paragraph{Limit-Curve Portal (Compactness Axis).} Invokes Ascoli-Arzel\`a or similar compactness arguments to extract convergent subsequences. Requires Fan Theorem (constructive) or Weak K\"onig's Lemma (classical reverse math).

\emph{GR examples:} Singularity theorems (G3).

\paragraph{Serial-Chain Portal (Choice Axis via DC).} Builds infinite sequences by dependent choice: $x_{n+1}$ depends on $x_0, \ldots, x_n$.

\emph{GR examples:} Some geodesic extension arguments.

\paragraph{Reductio Portal (Logic Axis).} Essential proof by contradiction: assume $\neg P$, derive contradiction, conclude $P$ for non-decidable $P$.

\emph{GR examples:} Singularity theorems (G3), uniqueness proofs (G2).

\subsection{Height Profiles}

An \textbf{AxisProfile} is a triple $(h_{\text{Choice}}, h_{\text{Comp}}, h_{\text{Logic}})$ where each component is 0, 1, or $\omega$:
\begin{itemize}
\item \textbf{Height 0:} No use of the corresponding axiom class
\item \textbf{Height 1:} Uses countable/dependent choice, Fan Theorem, or LEM for $\Sigma_0$ statements
\item \textbf{Height $\omega$:} Essential use at higher cardinalities or impredicative levels
\end{itemize}

\paragraph{Height 0 = Constructive at proof-route level.} A Height 0 proof performs finite symbolic computation, explicit construction, or decidable case analysis. No choice, compactness, or essential contradiction.

\subsection{The Five GR Targets}

\begin{center}
\begin{tabular}{llcl}
\toprule
\textbf{Target} & \textbf{Description} & \textbf{Profile} & \textbf{Status} \\
\midrule
G1 & Schwarzschild vacuum & $(0,0,0)$ & \textbf{Formalized} \\
G2 & Cauchy/MGHD existence & $(1,0,1)$ & Paper analysis \\
G3 & Singularity theorems & $(0,1,1)$ & Paper analysis \\
G4 & Maximal extensions & $(1,0,0)$ & Paper analysis \\
G5 & Computable evolution & Fails & Paper analysis \\
\bottomrule
\end{tabular}
\end{center}

\paragraph{G1 is Height 0.} The Schwarzschild vacuum check is finite symbolic computation: derivatives of $f(r) = 1 - 2M/r$, Christoffel formula application, index contraction, algebraic simplification. No portals crossed.

This is \textbf{unsurprising}---nobody would expect a textbook calculation to require Zorn. The value of formalizing G1 is not the Height 0 result itself, but demonstrating that the \AxCal{} tracking machinery works.

\paragraph{G2--G5 are where hidden axioms live.} These require non-trivial foundational commitments:
\begin{itemize}
\item G2: Zorn for maximality, reductio for uniqueness
\item G3: Compactness (limit-curve lemma), reductio (completeness $\Rightarrow$ contradiction)
\item G4: Zorn on extension posets
\item G5: Pour-El-Richards shows computable data can yield non-computable solutions
\end{itemize}

Formalizing these would be the valuable next step.

\subsection{What \AxCal{} Is Not}

\paragraph{Not a claim of novelty for reverse mathematics.} The correspondence between Zorn and AC, between Ascoli-Arzel\`a and WKL$_0$, between reductio and LEM is standard. \AxCal{} repackages these in GR-specific terminology.

\paragraph{Not a claim that Height 0 means ``constructive in Lean.''}  Our Lean formalization uses classical \texttt{mathlib} (with full LEM and choice). The Height 0 claim is about the \emph{proof route}, not the verification infrastructure. This distinction (``structural certification'') is philosophically debatable but organizationally useful.

\paragraph{Not a complete analysis.} The G2--G5 profiles are based on analyzing standard proofs. We do not prove these are \emph{optimal}---alternative proof routes might achieve lower heights.

% ===================================================================
% PART 4: THE FORMALIZATION
% ===================================================================

\section{The Lean 4 Formalization}
\label{sec:formalization}

\subsection{Repository Structure}

The formalization consists of three main files:

\begin{center}
\begin{tabular}{lrl}
\toprule
\textbf{File} & \textbf{Lines} & \textbf{Content} \\
\midrule
\texttt{Schwarzschild.lean} & $\sim$2,300 & Metric, Christoffel symbols, $f$ derivatives \\
\texttt{Riemann.lean} & $\sim$12,400 & Riemann components, Ricci tensor, symmetries \\
\texttt{Invariants.lean} & $\sim$1,300 & Kretschmann scalar, six-block decomposition \\
\bottomrule
\end{tabular}
\end{center}

Supporting files: \texttt{Interfaces.lean} (type definitions), \texttt{Compose.lean} (aggregators), \texttt{Certificates.lean} (\AxCal{} tracking stubs).

\subsection{Key Definitions}

\paragraph{Index type.}
\begin{leancode}
inductive Idx | t | r | theta | phi
  deriving DecidableEq, Fintype
\end{leancode}

\paragraph{Metric and inverse.}
\begin{leancode}
noncomputable def g (M : Real) : Idx -> Idx -> Real -> Real -> Real
| Idx.t, Idx.t, r, _ => -(f M r)
| Idx.r, Idx.r, r, _ => (f M r)^-1
| Idx.theta, Idx.theta, r, _ => r^2
| Idx.phi, Idx.phi, r, theta => r^2 * (Real.sin theta)^2
| _, _, _, _ => 0
\end{leancode}

\paragraph{Christoffel aggregator.}
\begin{leancode}
noncomputable def GammaTot (M : Real) : Idx -> Idx -> Idx -> Real -> Real -> Real
| Idx.t, Idx.t, Idx.r, r, _ => M / (r^2 * f M r)
| Idx.r, Idx.t, Idx.t, r, _ => M * f M r / r^2
-- ... 9 non-zero cases ...
| _, _, _, _, _ => 0
\end{leancode}

\subsection{Main Theorems}

\paragraph{Vacuum equations.}
\begin{leancode}
theorem Ricci_vanishes (M r theta : Real)
    (hM : 0 < M) (hr : 2*M < r) (hTheta : 0 < theta and theta < Real.pi) :
    forall mu nu : Idx, Ricci M r theta mu nu = 0
\end{leancode}

\paragraph{Kretschmann invariant.}
\begin{leancode}
theorem Kretschmann_value (M r theta : Real)
    (hM : 0 < M) (hr : 2*M < r) (hTheta : 0 < theta and theta < Real.pi) :
    Kretschmann M r theta = 48 * M^2 / r^6
\end{leancode}

\subsection{Proof Sketch and File Roles}

\paragraph{File roles.}
\begin{itemize}
\item \texttt{Schwarzschild.lean}: defines the Schwarzschild metric $g$, its inverse $g^{-1}$, and the nonzero Christoffel symbols $\Gamma^a_{bc}$ (collected in \texttt{GammaTot}). It proves the required derivative lemmas for $f(r)=1-\frac{2M}{r}$ and the basic smoothness facts on the exterior domain.
\item \texttt{Riemann.lean}: defines the Riemann tensor by the standard coordinate formula
\[
R^{\rho}{}_{\sigma\mu\nu}=\partial_{\mu}\Gamma^{\rho}{}_{\sigma\nu}-\partial_{\nu}\Gamma^{\rho}{}_{\sigma\mu}
\;+\;\Gamma^{\rho}{}_{\lambda\mu}\Gamma^{\lambda}{}_{\sigma\nu}-\Gamma^{\rho}{}_{\lambda\nu}\Gamma^{\lambda}{}_{\sigma\mu},
\]
proves its symmetries, evaluates all nonzero components, and shows the Ricci tensor $R_{\mu\nu}=R^{\alpha}{}_{\mu\alpha\nu}$ vanishes.
\item \texttt{Invariants.lean}: defines the Kretschmann scalar $K=R_{abcd}R^{abcd}$, proves the six-block decomposition using Riemann symmetries, and performs the final algebraic reduction to $48M^2/r^6$.
\end{itemize}

\paragraph{Key internal lemmas (selected).}
\begin{itemize}
\item \texttt{sumIdx}, \texttt{sumIdx\_expand}, \texttt{sumIdx\_mul\_sumIdx\_swap}: finite-index summation machinery and Fubini-style reordering.
\item \texttt{GammaTot\_symm}, \texttt{g\_symm}: symmetry lemmas for Christoffel and metric components.
\item \texttt{Riemann\_via\_Gamma1}: the core identity rewriting $R_{\beta a r \theta}$ in terms of $\partial \Gamma_1$ and $\Gamma\Gamma$ terms.
\item \texttt{R\_tr\_**\_zero} family: systematic vanishing of off-diagonal components.
\item \texttt{sixBlock} family: reduces 256-term Kretschmann sum to six weighted blocks.
\end{itemize}

\paragraph{Lean tactic patterns.}
The working proofs rely on short, reliable algebraic pipelines:
\begin{itemize}
\item \texttt{simp only} with explicit lemma lists (to avoid simp loops)
\item \texttt{simp\_rw} for controlled rewriting of sumIdx/GammaTot expansions
\item \texttt{field\_simp} to clear denominators in $f(r)^{-1}$ and $r^{-2}$
\item \texttt{ring\_nf} or \texttt{abel} for normalization and cancellation
\end{itemize}

\paragraph{Dependency diagram (key lemmas and files).}
\begin{figure}[h]
\centering
\begin{Verbatim}[fontsize=\small]
Interfaces.lean --+
Compose.lean    --+--> Schwarzschild.lean --> Riemann.lean --> Invariants.lean
Certificates.lean-+        |                    |                  |
  (AxCal stubs)            |                    |                  |
                           v                    v                  v
                    GammaTot, g, f-derivs  Riemann_via_Gamma1, R_*_zero  sixBlock, Kretschmann_value
\end{Verbatim}
\caption{High-level dependency flow. Core lemmas in each file feed the next stage of the Schwarzschild pipeline.}
\end{figure}

\paragraph{Human-readable proof sketch (G1).}
The Lean proof follows the textbook pipeline but makes every hypothesis explicit (e.g., $r>2M$ and $0<\theta<\pi$) and every cancellation justified.
\begin{enumerate}
\item \textbf{Domain and metric.} Fix the exterior region $r>2M$ with $0<\theta<\pi$. Define the Schwarzschild metric in Schwarzschild coordinates:
\[
g_{tt}=-(1-\tfrac{2M}{r}),\quad g_{rr}=(1-\tfrac{2M}{r})^{-1},\quad g_{\theta\theta}=r^2,\quad g_{\phi\phi}=r^2\sin^2\theta.
\]
Lean also defines $g^{-1}$ explicitly and proves $g^{-1}g=\mathrm{Id}$ componentwise under $r\neq 0$ and $\sin\theta\neq 0$.
\item \textbf{Christoffel symbols.} Use the coordinate formula for $\Gamma^a_{bc}$ and a case split over indices to show only the standard nine symbols are nonzero. In the exterior region with $f(r)=1-\frac{2M}{r}$, the nonzero symbols are:
\[
\Gamma^t_{tr}=\Gamma^t_{rt}=\frac{M}{r^2 f},\quad
\Gamma^r_{tt}=\frac{M f}{r^2},\quad
\Gamma^r_{rr}=-\frac{M}{r^2 f},
\]
\[
\Gamma^r_{\theta\theta}=-(r-2M),\quad
\Gamma^r_{\phi\phi}=-(r-2M)\sin^2\theta,\quad
\Gamma^\theta_{r\theta}=\Gamma^\theta_{\theta r}=\frac{1}{r},
\]
\[
\Gamma^\theta_{\phi\phi}=-\sin\theta\cos\theta,\quad
\Gamma^\phi_{r\phi}=\Gamma^\phi_{\phi r}=\frac{1}{r},\quad
\Gamma^\phi_{\theta\phi}=\Gamma^\phi_{\phi\theta}=\cot\theta.
\]
Lean proves these closed forms and their derivatives (e.g., $\partial_r f$ and $\partial_\theta\sin^2\theta$) with explicit differentiability lemmas on the exterior domain.
\item \textbf{Riemann tensor.} Define $R^\rho{}_{\sigma\mu\nu}$ by the coordinate formula above. Expand each nonzero component with the \texttt{GammaTot} aggregator, use symmetry identities
$R_{abcd}=-R_{bacd}=-R_{abdc}=R_{cdab}$, and show all off-diagonal components vanish by case analysis.
\item \textbf{Ricci tensor.} Contract indices to form $R_{\mu\nu}$. Each diagonal component is a finite sum of nonzero terms that cancel; Lean proves these cancellations by explicit rewriting and algebraic normalization (\texttt{ring\_nf}, \texttt{field\_simp}).
\item \textbf{Kretschmann scalar.} Expand $K=R_{abcd}R^{abcd}$ as a finite sum over $4^4=256$ index combinations. Using Riemann symmetries and vanishing components, the sum collapses to six independent blocks (\texttt{sixBlock}). Each block is evaluated and the weighted sum reduces to $48M^2/r^6$.
\end{enumerate}

\paragraph{Comparison with \emph{Gravitation} (MTW).}
MTW (and Wald/Carroll) present essentially the same coordinate computation, but at a narrative level: many cancellations are asserted by symmetry or ``by inspection,'' and domain hypotheses (e.g., $\sin\theta\neq 0$ or $r\neq 0$) are implicit. Lean forces every derivative, index contraction, and algebraic simplification to be explicit, and it surfaces which hypotheses are actually required. The formalization therefore mirrors MTW's flow but replaces informal steps with explicit, mechanically checked reductions.

\paragraph{Novelty and limits.}
There is no new physics here: the Schwarzschild vacuum check and Kretschmann invariant are textbook results. The novelty is methodological: (i) a complete, checkable proof in Lean 4, (ii) a detailed map of the proof's dependency structure, and (iii) a reusable infrastructure for future GR formalizations (e.g., alternative metrics or coordinate systems). The exercise highlights how ``easy'' GR calculations hide a large amount of formal bookkeeping.

\paragraph{Axioms and reverse-math perspective.}
At the level of mathematical content, the proof is \emph{Height 0}: it is a finite symbolic computation with no need for choice, compactness, or non-constructive existence arguments. That said, the current Lean development sits inside mathlib's classical environment, which assumes classical logic and standard real analysis facts (e.g., completeness of $\mathbb{R}$). The project therefore does not claim a fully constructive foundation; instead it identifies which axioms are actually \emph{used} in the GR pipeline. The formalization also makes hidden hypotheses explicit (e.g., $r\neq 0$, $\sin\theta\neq 0$, $f(r)\neq 0$), clarifying the minimal domain required for each step.

\subsection{What Is Verified (and What Is Not)}

\paragraph{Verified.} The Lean development verifies the Schwarzschild vacuum calculation in a single coordinate patch: explicit Christoffel symbols, all Riemann components, vanishing Ricci tensor, and the Kretschmann scalar in the exterior region $r>2M$ with $0<\theta<\pi$.

\paragraph{Not verified.} This does \emph{not} prove the full Einstein field equations or global properties of the spacetime, nor does it formalize coordinate changes, maximal extensions, or causal structure. It is a formal check of a standard coordinate computation, not a complete GR formalization.

\subsection{Build Status}

As of February 2026:
\begin{itemize}
\item \texttt{lake build Papers.P5\_GeneralRelativity.GR.Invariants}: \textbf{Success}
\item \texttt{lake build Papers.P5\_GeneralRelativity.GR.Riemann}: \textbf{Success}
\item \texttt{rg --glob '*.lean' -n '\textbackslash bsorry\textbackslash b' Papers/P5\_GeneralRelativity/GR}: \textbf{No results}
\item Builds should be run from the project root (the directory containing \texttt{lakefile.lean}).
\end{itemize}

Zero errors, zero sorries in the GR folder. (There remain lint warnings such as \texttt{unnecessarySimpa} and \texttt{unusedSimpArgs}; these do not affect correctness but indicate cleanup opportunities.)

% ===================================================================
% PART 5: MULTI-AI WORKFLOW
% ===================================================================

\section{Multi-AI Agent Collaboration}
\label{sec:ai}

This project was produced by four AI agents under human direction over six months (April--October 2025).

\subsection{Agent Roles}

\paragraph{Claude Code (Opus 4.5).} Primary implementation and tactical coding.
\begin{itemize}
\item Repository setup, namespace organization, CI/CD
\item Index type design (\texttt{Idx}, \texttt{sumIdx}, \texttt{GammaTot})
\item Refactoring when early approaches hit complexity walls
\item Build system maintenance across \texttt{mathlib} updates
\end{itemize}

\paragraph{GPT-5.2.} Mathematical strategy and theorem formulation.
\begin{itemize}
\item Theorem formulation with minimal dependency choices
\item Proof strategy for bottleneck identities
\item Tactic selection and algebraic normalization guidance
\item Key breakthrough: identified need for $C^2$ smoothness lemma
\end{itemize}

\paragraph{Gemini 2.5 Pro Deep Think (Google).} Strategic guidance.
\begin{itemize}
\item Theorem formulation: minimal dependency choices
\item Kretschmann six-block strategy: reduce 256 terms to 6
\item Literature correlation: mapping to MTW chapters
\item \AxCal{} framework validation
\end{itemize}

\paragraph{GPT-5.2 Codex (late-stage).} Code cleanup and refactoring.
\begin{itemize}
\item Lint-driven cleanup (unused simp arguments, unreachable tactics)
\item Simplification of differentiability lemmas and helper proofs
\item Paper edits to reflect build status and workflow
\end{itemize}

\subsection{Human Role}

\begin{enumerate}
\item \textbf{Goal setting:} Defined G1--G5 targets and \AxCal{} framework
\item \textbf{Agent coordination:} Directed which AI handled which task
\item \textbf{Quality control:} Reviewed all AI-generated code for correctness, clarity, maintainability
\end{enumerate}

\subsection{Lessons Learned}

\paragraph{What worked:}
\begin{itemize}
\item Specialization: Different agents have different strengths
\item Iteration: Multiple rounds of generation/review/refinement
\item Documentation: Agents document their own reasoning
\end{itemize}

\paragraph{What didn't work:}
\begin{itemize}
\item Aggressive automation (\texttt{simp} explosions)
\item Assuming \texttt{mathlib} has what you need (it often doesn't)
\item Large monolithic proofs (need to break into lemmas)
\end{itemize}

% ===================================================================
% PART 6: LIMITATIONS AND FUTURE WORK
% ===================================================================

\section{Limitations and Future Work}
\label{sec:limitations}

\subsection{What We Did Not Prove}

\begin{itemize}
\item \textbf{Behavior at $r = 2M$:} The event horizon is a coordinate singularity. Extending to Kruskal-Szekeres coordinates would require additional formalization (~50--100 hours).

\item \textbf{Behavior at poles $\theta = 0, \pi$:} Coordinate singularity in spherical coordinates. Extending would require stereographic patch (~40--60 hours).

\item \textbf{Global structure:} We work in a single coordinate chart. Full manifold theory with atlas, transition functions, coordinate-independent tensors is not formalized.

\item \textbf{G2--G5:} The interesting cases with hidden axioms are paper-level analysis only.
\end{itemize}

\subsection{Future Directions}

\paragraph{Short-term (builds on current work):}
\begin{enumerate}
\item Add stereographic coordinate patch for poles
\item Prove coordinate transformations preserve curvature
\item Extend to Reissner-Nordstr\"om (charged), Kerr (rotating)
\end{enumerate}

\paragraph{Medium-term (substantial new work):}
\begin{enumerate}
\item Formalize Kruskal-Szekeres coordinates, prove regularity at horizon
\item Formalize Cauchy problem (G2)---local PDE well-posedness
\item Build manifold atlas machinery
\end{enumerate}

\paragraph{Long-term (research-level):}
\begin{enumerate}
\item Formalize singularity theorems (G3)---requires global causal structure
\item Formalize Pour-El-Richards (G5)---requires computability theory in Lean
\item Prove height profiles are \emph{optimal} (no lower-height proof exists)
\end{enumerate}

\section{Conclusion}

We have presented the first complete formal verification of Schwarzschild curvature calculations in Lean 4. The formalization demonstrates that formal GR is feasible, documents why ``trivial'' mathematics is hard to formalize, and provides infrastructure for future work.

The \AxCal{} framework offers an organizational methodology for tracking axiomatic dependencies in physics. While the Height 0 result for G1 is unsurprising, the framework is positioned for application to G2--G5, where hidden axioms actually appear.

The multi-AI agent workflow (Claude Code Opus 4.5, GPT-5.2, Gemini 2.5 Pro Deep Think, GPT-5.2 Codex) represents a case study in AI-assisted theorem proving, showing how different AI strengths complement each other.

The value of this work is the \emph{artifact} and the \emph{program} it initiates, not new mathematics. We have demonstrated feasibility and provided a foundation for more ambitious formalizations of General Relativity.

\section*{Acknowledgments}

The author thanks the AI agents (Claude Code Opus 4.5, GPT-5.2, Gemini 2.5 Pro Deep Think, GPT-5.2 Codex) for their contributions to the formalization. All errors remain the author's responsibility.

\bibliographystyle{plain}
\bibliography{../references}

\end{document}
